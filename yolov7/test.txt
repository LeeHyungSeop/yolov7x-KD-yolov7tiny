YOLOR 🚀 8c82880 torch 2.4.0 CUDA:0 (NVIDIA GeForce RTX 3060, 12287.5MB)

Namespace(weights='yolo7.pt', cfg='', teacher_weights='yolov7x.pt', student_weights='yolov7-tiny.pt', teacher_cfg='cfg/training/yolov7x.yaml', student_cfg='cfg/training/yolov7-tiny.yaml', data='../dataset/data.yaml', hyp='./runs/train/coco_v7tiny_person_10000_finetuning_result/hyp.yaml', epochs=100, batch_size=4, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=4, project='runs/train', entity=None, name='KD_v7x_to_v7tiny_person_10000_result', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/KD_v7x_to_v7tiny_person_10000_result8', total_batch_size=4)
[34m[1mtensorboard: [0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/
[34m[1mhyperparameters: [0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1
/home/hslee/YOLOv7_KD/yolov7/train.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  student_run_id = torch.load(student_weights, map_location=device).get('wandb_id') if student_weights.endswith('.pt') and os.path.isfile(student_weights) else None
/home/hslee/YOLOv7_KD/yolov7/train.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(teacher_weights, map_location=device)  # load checkpoint
Overriding model.yaml nc=80 with nc=1

                 from  n    params  module                                  arguments                     
  0                -1  1      1160  models.common.Conv                      [3, 40, 3, 1]                 
  1                -1  1     28960  models.common.Conv                      [40, 80, 3, 2]                
  2                -1  1     57760  models.common.Conv                      [80, 80, 3, 1]                
  3                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               
  4                -1  1     10368  models.common.Conv                      [160, 64, 1, 1]               
  5                -2  1     10368  models.common.Conv                      [160, 64, 1, 1]               
  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                
  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                
  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                
  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                
 10                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                
 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                
 12[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           
 13                -1  1    103040  models.common.Conv                      [320, 320, 1, 1]              
 14                -1  1         0  models.common.MP                        []                            
 15                -1  1     51520  models.common.Conv                      [320, 160, 1, 1]              
 16                -3  1     51520  models.common.Conv                      [320, 160, 1, 1]              
 17                -1  1    230720  models.common.Conv                      [160, 160, 3, 2]              
 18          [-1, -3]  1         0  models.common.Concat                    [1]                           
 19                -1  1     41216  models.common.Conv                      [320, 128, 1, 1]              
 20                -2  1     41216  models.common.Conv                      [320, 128, 1, 1]              
 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 23                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 24                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 25                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 26                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 27[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           
 28                -1  1    410880  models.common.Conv                      [640, 640, 1, 1]              
 29                -1  1         0  models.common.MP                        []                            
 30                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              
 31                -3  1    205440  models.common.Conv                      [640, 320, 1, 1]              
 32                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              
 33          [-1, -3]  1         0  models.common.Concat                    [1]                           
 34                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              
 35                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              
 36                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 37                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 38                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 39                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 40                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 41                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 42[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           
 43                -1  1   1640960  models.common.Conv                      [1280, 1280, 1, 1]            
 44                -1  1         0  models.common.MP                        []                            
 45                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             
 46                -3  1    820480  models.common.Conv                      [1280, 640, 1, 1]             
 47                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              
 48          [-1, -3]  1         0  models.common.Concat                    [1]                           
 49                -1  1    328192  models.common.Conv                      [1280, 256, 1, 1]             
 50                -2  1    328192  models.common.Conv                      [1280, 256, 1, 1]             
 51                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 52                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 53                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 54                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 55                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 56                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 57[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           
 58                -1  1   1640960  models.common.Conv                      [1280, 1280, 1, 1]            
 59                -1  1  11887360  models.common.SPPCSPC                   [1280, 640, 1]                
 60                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              
 61                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 62                43  1    410240  models.common.Conv                      [1280, 320, 1, 1]             
 63          [-1, -2]  1         0  models.common.Concat                    [1]                           
 64                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              
 65                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              
 66                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 67                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 68                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 69                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 70                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 71                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 72[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           
 73                -1  1    410240  models.common.Conv                      [1280, 320, 1, 1]             
 74                -1  1     51520  models.common.Conv                      [320, 160, 1, 1]              
 75                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 76                28  1    102720  models.common.Conv                      [640, 160, 1, 1]              
 77          [-1, -2]  1         0  models.common.Concat                    [1]                           
 78                -1  1     41216  models.common.Conv                      [320, 128, 1, 1]              
 79                -2  1     41216  models.common.Conv                      [320, 128, 1, 1]              
 80                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 81                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 82                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 83                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              
 86[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           
 87                -1  1    102720  models.common.Conv                      [640, 160, 1, 1]              
 88                -1  1         0  models.common.MP                        []                            
 89                -1  1     25920  models.common.Conv                      [160, 160, 1, 1]              
 90                -3  1     25920  models.common.Conv                      [160, 160, 1, 1]              
 91                -1  1    230720  models.common.Conv                      [160, 160, 3, 2]              
 92      [-1, -3, 73]  1         0  models.common.Concat                    [1]                           
 93                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              
 94                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              
 95                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 96                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
100                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              
101[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           
102                -1  1    410240  models.common.Conv                      [1280, 320, 1, 1]             
103                -1  1         0  models.common.MP                        []                            
104                -1  1    103040  models.common.Conv                      [320, 320, 1, 1]              
105                -3  1    103040  models.common.Conv                      [320, 320, 1, 1]              
106                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              
107      [-1, -3, 59]  1         0  models.common.Concat                    [1]                           
108                -1  1    656384  models.common.Conv                      [1280, 512, 1, 1]             
109                -2  1    656384  models.common.Conv                      [1280, 512, 1, 1]             
110                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              
111                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              
112                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              
113                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              
114                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              
115                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              
116[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           
117                -1  1   1639680  models.common.Conv                      [2560, 640, 1, 1]             
118                87  1    461440  models.common.Conv                      [160, 320, 3, 1]              
119               102  1   1844480  models.common.Conv                      [320, 640, 3, 1]              
120               117  1   7375360  models.common.Conv                      [640, 1280, 3, 1]             
121   [118, 119, 120]  1     42668  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [320, 640, 1280]]
/root/anaconda3/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/TensorShape.cpp:3609.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 467 layers, 70815092 parameters, 70815092 gradients, 188.9 GFLOPS

Transferred 630/644 items from yolov7x.pt
Overriding model.yaml nc=80 with nc=1

                 from  n    params  module                                  arguments                     
  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]
  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  8                -1  1         0  models.common.MP                        []                            
  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 15                -1  1         0  models.common.MP                        []                            
 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 22                -1  1         0  models.common.MP                        []                            
 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 31                -1  1         0  models.common.SP                        [5]                           
 32                -2  1         0  models.common.SP                        [9]                           
 33                -3  1         0  models.common.SP                        [13]                          
 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 36          [-1, -7]  1         0  models.common.Concat                    [1]                           
 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 41          [-1, -2]  1         0  models.common.Concat                    [1]                           
 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 51          [-1, -2]  1         0  models.common.Concat                    [1]                           
 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]
 59          [-1, 47]  1         0  models.common.Concat                    [1]                           
 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]
 67          [-1, 37]  1         0  models.common.Concat                    [1]                           
 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           
 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 77      [74, 75, 76]  1     17132  models.yolo.IDetect                     [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
Model Summary: 263 layers, 6014988 parameters, 6014988 gradients, 13.2 GFLOPS

Transferred 77/344 items from yolov7-tiny.pt
Scaled weight_decay = 0.0005
student_optimizer groups: 58 .bias, 58 conv.weight, 61 other
/home/hslee/YOLOv7_KD/yolov7/utils/datasets.py:394: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  cache, exists = torch.load(cache_path), True  # load
[34m[1mwandb: [0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)
pretrained : True
teacher_weights : yolov7x.pt
teacher_cfg : cfg/training/yolov7x.yaml
student_cfg : cfg/training/yolov7-tiny.yaml

[34m[1mtrain: [0mScanning '../dataset/train.cache' images and labels... 8000 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 8000/8000 [00:00<?, ?it/s]
[34m[1mtrain: [0mScanning '../dataset/train.cache' images and labels... 8000 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 8000/8000 [00:00<?, ?it/s]

[34m[1mval: [0mScanning '../dataset/val.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 2000/2000 [00:00<?, ?it/s]
[34m[1mval: [0mScanning '../dataset/val.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 2000/2000 [00:00<?, ?it/s]
/home/hslee/YOLOv7_KD/yolov7/train.py:338: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=cuda)
Image sizes 640 train, 640 test
Using 4 dataloader workers
Logging results to runs/train/KD_v7x_to_v7tiny_person_10000_result8
Starting training for 100 epochs...

     Epoch   gpu_mem       box       obj       cls     total    labels  img_size

[34m[1mautoanchor: [0mAnalyzing anchors... anchors/target = 4.34, Best Possible Recall (BPR) = 0.9980
student_compute_loss_ota : <utils.loss.ComputeLossOTA object at 0x7f624ce87f70>
student_compute_loss : <utils.loss.ComputeLoss object at 0x7f624ce87340>

  0%|          | 0/2000 [00:00<?, ?it/s]/home/hslee/YOLOv7_KD/yolov7/train.py:409: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=cuda):

      0/99    0.667G   0.07802   0.02263         0    0.1007        33       640:   0%|          | 0/2000 [00:02<?, ?it/s]
      0/99    0.667G   0.07802   0.02263         0    0.1007        33       640:   0%|          | 1/2000 [00:02<1:35:40,  2.87s/it]
      0/99     1.42G   0.07776   0.02193         0   0.09969        22       640:   0%|          | 1/2000 [00:03<1:35:40,  2.87s/it]
      0/99     1.42G   0.07776   0.02193         0   0.09969        22       640:   0%|          | 2/2000 [00:03<43:19,  1.30s/it]  
      0/99      1.7G   0.07695   0.02019         0   0.09714        12       640:   0%|          | 2/2000 [00:03<43:19,  1.30s/it]
      0/99      1.7G   0.07695   0.02019         0   0.09714        12       640:   0%|          | 3/2000 [00:03<26:22,  1.26it/s]
      0/99      1.7G   0.07591   0.02063         0   0.09654        23       640:   0%|          | 3/2000 [00:03<26:22,  1.26it/s]
      0/99      1.7G   0.07591   0.02063         0   0.09654        23       640:   0%|          | 4/2000 [00:03<18:26,  1.80it/s]
      0/99      1.7G   0.07603   0.02103         0   0.09706        26       640:   0%|          | 4/2000 [00:03<18:26,  1.80it/s]
      0/99      1.7G   0.07603   0.02103         0   0.09706        26       640:   0%|          | 5/2000 [00:03<13:58,  2.38it/s]
      0/99      1.7G   0.07603   0.02104         0   0.09707        33       640:   0%|          | 5/2000 [00:03<13:58,  2.38it/s]
      0/99      1.7G   0.07603   0.02104         0   0.09707        33       640:   0%|          | 6/2000 [00:03<11:15,  2.95it/s]
      0/99      1.7G   0.07699   0.02057         0   0.09755        15       640:   0%|          | 6/2000 [00:03<11:15,  2.95it/s]
      0/99      1.7G   0.07699   0.02057         0   0.09755        15       640:   0%|          | 7/2000 [00:03<09:31,  3.49it/s]
      0/99      1.7G    0.0776   0.02057         0   0.09817        30       640:   0%|          | 7/2000 [00:04<09:31,  3.49it/s]
      0/99      1.7G    0.0776   0.02057         0   0.09817        30       640:   0%|          | 8/2000 [00:04<08:30,  3.90it/s]
      0/99      1.7G   0.07753   0.02043         0   0.09796        16       640:   0%|          | 8/2000 [00:04<08:30,  3.90it/s]
      0/99      1.7G   0.07753   0.02043         0   0.09796        16       640:   0%|          | 9/2000 [00:04<07:43,  4.30it/s]
      0/99      1.7G   0.07982   0.02004         0   0.09986        46       640:   0%|          | 9/2000 [00:04<07:43,  4.30it/s]
      0/99      1.7G   0.07982   0.02004         0   0.09986        46       640:   0%|          | 10/2000 [00:04<07:11,  4.61it/s]
      0/99      1.7G   0.07953   0.02025         0   0.09978        30       640:   0%|          | 10/2000 [00:04<07:11,  4.61it/s]
      0/99      1.7G   0.07953   0.02025         0   0.09978        30       640:   1%|          | 11/2000 [00:04<06:50,  4.85it/s]
      0/99      1.7G   0.08007    0.0199         0   0.09997        13       640:   1%|          | 11/2000 [00:04<06:50,  4.85it/s]
      0/99      1.7G   0.08007    0.0199         0   0.09997        13       640:   1%|          | 12/2000 [00:04<06:27,  5.13it/s]
      0/99      1.7G   0.07991   0.02006         0   0.09998        32       640:   1%|          | 12/2000 [00:05<06:27,  5.13it/s]
      0/99      1.7G   0.07991   0.02006         0   0.09998        32       640:   1%|          | 13/2000 [00:05<06:21,  5.21it/s]
      0/99      1.7G   0.08029   0.01973         0       0.1        12       640:   1%|          | 13/2000 [00:05<06:21,  5.21it/s]
      0/99      1.7G   0.08029   0.01973         0       0.1        12       640:   1%|          | 14/2000 [00:05<06:13,  5.32it/s]
      0/99      1.7G   0.08013   0.01998         0    0.1001        34       640:   1%|          | 14/2000 [00:05<06:13,  5.32it/s]
      0/99      1.7G   0.08013   0.01998         0    0.1001        34       640:   1%|          | 15/2000 [00:05<06:12,  5.34it/s]
      0/99      1.7G   0.07793   0.01975         0   0.09768         9       640:   1%|          | 15/2000 [00:05<06:12,  5.34it/s]
      0/99      1.7G   0.07793   0.01975         0   0.09768         9       640:   1%|          | 16/2000 [00:05<06:05,  5.43it/s]
      0/99      1.7G   0.07779   0.02008         0   0.09786        38       640:   1%|          | 16/2000 [00:05<06:05,  5.43it/s]
      0/99      1.7G   0.07779   0.02008         0   0.09786        38       640:   1%|          | 17/2000 [00:05<06:02,  5.47it/s]
      0/99      1.7G   0.07791   0.01993         0   0.09784        16       640:   1%|          | 17/2000 [00:05<06:02,  5.47it/s]
      0/99      1.7G   0.07791   0.01993         0   0.09784        16       640:   1%|          | 18/2000 [00:05<06:00,  5.50it/s]
      0/99      1.7G   0.07782   0.02033         0   0.09815        45       640:   1%|          | 18/2000 [00:06<06:00,  5.50it/s]
      0/99      1.7G   0.07782   0.02033         0   0.09815        45       640:   1%|          | 19/2000 [00:06<06:03,  5.45it/s]
      0/99      1.7G   0.07786   0.02115         0   0.09901        82       640:   1%|          | 19/2000 [00:06<06:03,  5.45it/s]
      0/99      1.7G   0.07786   0.02115         0   0.09901        82       640:   1%|          | 20/2000 [00:06<06:05,  5.42it/s]
      0/99      1.7G     0.078   0.02159         0   0.09959        71       640:   1%|          | 20/2000 [00:06<06:05,  5.42it/s]
      0/99      1.7G     0.078   0.02159         0   0.09959        71       640:   1%|          | 21/2000 [00:06<06:08,  5.37it/s]
      0/99      1.7G   0.07785   0.02156         0   0.09941        27       640:   1%|          | 21/2000 [00:06<06:08,  5.37it/s]
      0/99      1.7G   0.07785   0.02156         0   0.09941        27       640:   1%|          | 22/2000 [00:06<06:11,  5.32it/s]
      0/99      1.7G   0.07746   0.02137         0   0.09883        10       640:   1%|          | 22/2000 [00:06<06:11,  5.32it/s]
      0/99      1.7G   0.07746   0.02137         0   0.09883        10       640:   1%|          | 23/2000 [00:06<06:03,  5.44it/s]
      0/99      1.7G   0.07749   0.02129         0   0.09879        26       640:   1%|          | 23/2000 [00:07<06:03,  5.44it/s]
      0/99      1.7G   0.07749   0.02129         0   0.09879        26       640:   1%|          | 24/2000 [00:07<06:07,  5.38it/s]
      0/99      1.7G   0.07748   0.02111         0   0.09859        14       640:   1%|          | 24/2000 [00:07<06:07,  5.38it/s]
      0/99      1.7G   0.07748   0.02111         0   0.09859        14       640:   1%|▏         | 25/2000 [00:07<05:56,  5.53it/s]
      0/99      1.7G   0.07721   0.02103         0   0.09824        18       640:   1%|▏         | 25/2000 [00:07<05:56,  5.53it/s]
      0/99      1.7G   0.07721   0.02103         0   0.09824        18       640:   1%|▏         | 26/2000 [00:07<05:55,  5.55it/s]
      0/99      1.7G   0.07722   0.02105         0   0.09827        24       640:   1%|▏         | 26/2000 [00:07<05:55,  5.55it/s]
      0/99      1.7G   0.07722   0.02105         0   0.09827        24       640:   1%|▏         | 27/2000 [00:07<05:59,  5.49it/s]
      0/99      1.7G   0.07711   0.02118         0   0.09829        38       640:   1%|▏         | 27/2000 [00:07<05:59,  5.49it/s]
      0/99      1.7G   0.07711   0.02118         0   0.09829        38       640:   1%|▏         | 28/2000 [00:07<05:59,  5.48it/s]
      0/99      1.7G   0.07711   0.02125         0   0.09836        36       640:   1%|▏         | 28/2000 [00:08<05:59,  5.48it/s]
      0/99      1.7G   0.07711   0.02125         0   0.09836        36       640:   1%|▏         | 29/2000 [00:08<06:01,  5.45it/s]
      0/99      1.7G   0.07735   0.02122         0   0.09857        31       640:   1%|▏         | 29/2000 [00:08<06:01,  5.45it/s]
      0/99      1.7G   0.07735   0.02122         0   0.09857        31       640:   2%|▏         | 30/2000 [00:08<06:02,  5.44it/s]
      0/99      1.7G   0.07719   0.02126         0   0.09845        29       640:   2%|▏         | 30/2000 [00:08<06:02,  5.44it/s]
      0/99      1.7G   0.07719   0.02126         0   0.09845        29       640:   2%|▏         | 31/2000 [00:08<06:02,  5.43it/s]
      0/99      1.7G   0.07696    0.0212         0   0.09815        20       640:   2%|▏         | 31/2000 [00:08<06:02,  5.43it/s]
      0/99      1.7G   0.07696    0.0212         0   0.09815        20       640:   2%|▏         | 32/2000 [00:08<06:02,  5.44it/s]
      0/99      1.7G     0.077   0.02141         0   0.09841        58       640:   2%|▏         | 32/2000 [00:08<06:02,  5.44it/s]
      0/99      1.7G     0.077   0.02141         0   0.09841        58       640:   2%|▏         | 33/2000 [00:08<06:07,  5.36it/s]
      0/99      1.7G   0.07715   0.02159         0   0.09874        65       640:   2%|▏         | 33/2000 [00:08<06:07,  5.36it/s]
      0/99      1.7G   0.07715   0.02159         0   0.09874        65       640:   2%|▏         | 34/2000 [00:08<06:13,  5.27it/s]
      0/99      1.7G   0.07715   0.02148         0   0.09862        17       640:   2%|▏         | 34/2000 [00:09<06:13,  5.27it/s]
      0/99      1.7G   0.07715   0.02148         0   0.09862        17       640:   2%|▏         | 35/2000 [00:09<06:08,  5.34it/s]
      0/99      1.7G   0.07717   0.02146         0   0.09863        30       640:   2%|▏         | 35/2000 [00:09<06:08,  5.34it/s]
      0/99      1.7G   0.07717   0.02146         0   0.09863        30       640:   2%|▏         | 36/2000 [00:09<06:06,  5.36it/s]
      0/99      1.7G   0.07719   0.02146         0   0.09865        31       640:   2%|▏         | 36/2000 [00:09<06:06,  5.36it/s]
      0/99      1.7G   0.07719   0.02146         0   0.09865        31       640:   2%|▏         | 37/2000 [00:09<06:05,  5.37it/s]
      0/99      1.7G   0.07718   0.02143         0   0.09861        28       640:   2%|▏         | 37/2000 [00:09<06:05,  5.37it/s]
      0/99      1.7G   0.07718   0.02143         0   0.09861        28       640:   2%|▏         | 38/2000 [00:09<06:00,  5.44it/s]
      0/99      1.7G   0.07722   0.02146         0   0.09868        35       640:   2%|▏         | 38/2000 [00:09<06:00,  5.44it/s]
      0/99      1.7G   0.07722   0.02146         0   0.09868        35       640:   2%|▏         | 39/2000 [00:09<05:59,  5.45it/s]
      0/99      1.7G   0.07745    0.0213         0   0.09874        14       640:   2%|▏         | 39/2000 [00:10<05:59,  5.45it/s]
      0/99      1.7G   0.07745    0.0213         0   0.09874        14       640:   2%|▏         | 40/2000 [00:10<05:57,  5.48it/s]